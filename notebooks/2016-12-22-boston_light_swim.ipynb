{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [The Boston Light Swim](http://bostonlightswim.org/)\n",
    "\n",
    "Fetching near real time Sea Surface Temperature time-series data from all avialble source and compare them.\n",
    "\n",
    "For more information regaridng the workflow presented here see [Signell, Richard P.; Fernandes, Filipe; Wilcox, Kyle.\t2016. \"Dynamic Reusable Workflows for Ocean Science.\" *J. Mar. Sci. Eng.* 4, no. 4: 68](http://dx.doi.org/10.3390/jmse4040068)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "ioos_tools = os.path.join(os.path.pardir)\n",
    "sys.path.append(ioos_tools)\n",
    "\n",
    "# Suppresing warnings for a \"pretty output.\"\n",
    "# Remove this line to debug any possible issues.\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.yaml\n",
    "\n",
    "# Specify a YYYY-MM-DD hh:mm:ss date or integer day offset.\n",
    "# If both start and stop are offsets they will be computed relative to datetime.today() at midnight.\n",
    "# Use the dates commented below to reproduce the last Boston Light Swim event forecast.\n",
    "date:\n",
    "    start: -5 # 2016-8-16 00:00:00\n",
    "    stop: +4 # 2016-8-29 00:00:00\n",
    "\n",
    "run_name: 'latest'\n",
    "\n",
    "# Boston harbor.\n",
    "region:\n",
    "    bbox: [-71.3, 42.03, -70.57, 42.63]\n",
    "    crs: 'urn:ogc:def:crs:OGC:1.3:CRS84'\n",
    "\n",
    "sos_name: 'sea_water_temperature'\n",
    "\n",
    "cf_names:\n",
    "    - sea_water_temperature\n",
    "    - sea_surface_temperature\n",
    "    - sea_water_potential_temperature\n",
    "    - equivalent_potential_temperature\n",
    "    - sea_water_conservative_temperature\n",
    "    - pseudo_equivalent_potential_temperature\n",
    "\n",
    "units: 'celsius'\n",
    "\n",
    "catalogs:\n",
    "    - https://www.ngdc.noaa.gov/geoportal/csw\n",
    "    - https://data.ioos.us/csw\n",
    "    - http://gamone.whoi.edu/csw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data inside directory /home/filipe/IOOS/notebooks_demos/notebooks/latest\n",
      "*********************** Run information ************************\n",
      "Run date: 2016-12-22 14:53:01\n",
      "Start: 2016-12-17 00:00:00\n",
      "Stop: 2016-12-26 00:00:00\n",
      "Bounding box: -71.30, 42.03,-70.57, 42.63\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from ioos_tools.ioos import parse_config\n",
    "\n",
    "config = parse_config('config.yaml')\n",
    "\n",
    "save_dir = os.path.abspath(config['run_name'])\n",
    "\n",
    "\n",
    "fmt = '{:*^64}'.format\n",
    "print(fmt('Saving data inside directory {}'.format(save_dir)))\n",
    "print(fmt(' Run information '))\n",
    "print('Run date: {:%Y-%m-%d %H:%M:%S}'.format(datetime.utcnow()))\n",
    "print('Start: {:%Y-%m-%d %H:%M:%S}'.format(config['date']['start']))\n",
    "print('Stop: {:%Y-%m-%d %H:%M:%S}'.format(config['date']['stop']))\n",
    "print('Bounding box: {0:3.2f}, {1:3.2f},'\n",
    "         '{2:3.2f}, {3:3.2f}'.format(*config['region']['bbox']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the data filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_filter(config):\n",
    "    from owslib import fes\n",
    "    from ioos_tools.ioos import fes_date_filter\n",
    "    kw = dict(wildCard='*', escapeChar='\\\\',\n",
    "              singleChar='?', propertyname='apiso:AnyText')\n",
    "\n",
    "    or_filt = fes.Or([fes.PropertyIsLike(literal=('*%s*' % val), **kw)\n",
    "                      for val in config['cf_names']])\n",
    "\n",
    "    # Exclude ROMS Averages and History files.\n",
    "    not_filt = fes.Not([fes.PropertyIsLike(literal='*Averages*', **kw)])\n",
    "\n",
    "    begin, end = fes_date_filter(config['date']['start'],\n",
    "                                 config['date']['stop'])\n",
    "    bbox_crs = fes.BBox(config['region']['bbox'],\n",
    "                        crs=config['region']['crs'])\n",
    "    return [fes.And([bbox_crs, begin, end, or_filt, not_filt])]\n",
    "\n",
    "\n",
    "filter_list = make_filter(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************* Catalog information **********************\n",
      "URL: https://www.ngdc.noaa.gov/geoportal/csw\n",
      "Number of datasets available: 1\n",
      "HYbrid Coordinate Ocean Model (HYCOM): Global\n",
      "\n",
      "\n",
      "URL: https://data.ioos.us/csw\n",
      "Number of datasets available: 10\n",
      "NAM CONUS 20km/Best NAM CONUS 20km Time Series\n",
      "Rapid Refresh CONUS 13km/Best Rapid Refresh CONUS 13km Time Series\n",
      "DGEX CONUS 12km/Best DGEX CONUS 12km Time Series\n",
      "NAM CONUS 80km/Best NAM CONUS 80km Time Series\n",
      "NOAA/NCEP Global Forecast System (GFS) Atmospheric Model\n",
      "NAM Alaska 11km/Best NAM Alaska 11km Time Series\n",
      "FNMOC COAMPS Western Atlantic/Best FNMOC COAMPS Western Atlantic Time Series\n",
      "NAM Alaska 45km from NOAAPORT/Best NAM Alaska 45km from NOAAPORT Time Series\n",
      "NAM Alaska 22km/Best NAM Alaska 22km Time Series\n",
      "Rapid Refresh CONUS 40km/Best Rapid Refresh CONUS 40km Time Series\n",
      "***************************** DAP ******************************\n",
      "http://oos.soest.hawaii.edu/thredds/dodsC/hioos/model/atm/ncep_global/NCEP_Global_Atmospheric_Model_best.ncd.html\n",
      "http://thredds.ucar.edu/thredds/dodsC/grib/FNMOC/COAMPS/Western_Atlantic/Best.html\n",
      "http://thredds.ucar.edu/thredds/dodsC/grib/NCEP/DGEX/CONUS_12km/Best.html\n",
      "http://thredds.ucar.edu/thredds/dodsC/grib/NCEP/NAM/Alaska_11km/Best.html\n",
      "http://thredds.ucar.edu/thredds/dodsC/grib/NCEP/NAM/Alaska_22km/Best.html\n",
      "http://thredds.ucar.edu/thredds/dodsC/grib/NCEP/NAM/Alaska_45km/noaaport/Best.html\n",
      "http://thredds.ucar.edu/thredds/dodsC/grib/NCEP/NAM/CONUS_20km/noaaport/Best.html\n",
      "http://thredds.ucar.edu/thredds/dodsC/grib/NCEP/NAM/CONUS_80km/Best.html\n",
      "http://thredds.ucar.edu/thredds/dodsC/grib/NCEP/RAP/CONUS_13km/Best.html\n",
      "http://thredds.ucar.edu/thredds/dodsC/grib/NCEP/RAP/CONUS_40km/Best.html\n",
      "\n",
      "\n",
      "URL: http://gamone.whoi.edu/csw\n",
      "Number of datasets available: 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ioos_tools.ioos import service_urls\n",
    "from owslib.csw import CatalogueServiceWeb\n",
    "\n",
    "\n",
    "dap_urls = []\n",
    "sos_urls = []\n",
    "print(fmt(' Catalog information '))\n",
    "for endpoint in config['catalogs']:\n",
    "    print(\"URL: {}\".format(endpoint))\n",
    "\n",
    "    csw = CatalogueServiceWeb(endpoint, timeout=120)\n",
    "    csw.getrecords2(constraints=filter_list, maxrecords=1000, esn='full')\n",
    "    dap = service_urls(csw.records, identifier='OPeNDAP:OPeNDAP')\n",
    "    dap2 = service_urls(csw.records, identifier='urn:x-esri:specification:ServiceType:odp:url')\n",
    "    sos = service_urls(csw.records, identifier='OGC:SOS')\n",
    "    dap_urls.extend(dap)\n",
    "    dap_urls.extend(dap2)\n",
    "    sos_urls.extend(sos)\n",
    "\n",
    "    print(\"Number of datasets available: {}\".format(len(csw.records.keys())))\n",
    "\n",
    "    for rec, item in csw.records.items():\n",
    "        print('{}'.format(item.title))\n",
    "    if sos:\n",
    "        print(fmt(' SOS '))\n",
    "        for url in sos:\n",
    "            print('{}'.format(url))\n",
    "    if dap:\n",
    "        print(fmt(' DAP '))\n",
    "        for url in dap:\n",
    "            print('{}.html'.format(url))\n",
    "    print('\\n')\n",
    "\n",
    "# Get only unique endpoints.\n",
    "dap_urls = list(set(dap_urls))\n",
    "sos_urls = list(set(sos_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ioos_tools.ioos import is_station\n",
    "\n",
    "# Filter out some station endpoints.\n",
    "non_stations = []\n",
    "for url in dap_urls:\n",
    "    try:\n",
    "        if not is_station(url):\n",
    "            non_stations.append(url)\n",
    "    except (RuntimeError, OSError) as e:\n",
    "        log.warn(\"Could not access URL {}. {!r}\".format(url, e))\n",
    "\n",
    "dap_urls = non_stations\n",
    "\n",
    "print(fmt(' Filtered DAP '))\n",
    "for url in dap_urls:\n",
    "    print('{}.html'.format(url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NdbcSos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyoos.collectors.ndbc.ndbc_sos import NdbcSos\n",
    "\n",
    "collector_ndbc = NdbcSos()\n",
    "\n",
    "collector_ndbc.set_bbox(config['region']['bbox'])\n",
    "collector_ndbc.end_time = config['date']['stop']\n",
    "collector_ndbc.start_time = config['date']['start']\n",
    "collector_ndbc.variables = [config['sos_name']]\n",
    "\n",
    "ofrs = collector_ndbc.server.offerings\n",
    "title = collector_ndbc.server.identification.title\n",
    "print(fmt(' NDBC Collector offerings '))\n",
    "print('{}: {} offerings'.format(title, len(ofrs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ioos_tools.ioos import collector2table, to_html\n",
    "\n",
    "ndbc = collector2table(collector=collector_ndbc,\n",
    "                       config=config,\n",
    "                       col='sea_water_temperature (C)')\n",
    "\n",
    "if ndbc:\n",
    "    data = dict(\n",
    "        station_name=[s._metadata.get('station_name') for s in ndbc],\n",
    "        station_code=[s._metadata.get('station_code') for s in ndbc],\n",
    "        sensor=[s._metadata.get('sensor') for s in ndbc],\n",
    "        lon=[s._metadata.get('lon') for s in ndbc],\n",
    "        lat=[s._metadata.get('lat') for s in ndbc],\n",
    "        depth=[s._metadata.get('depth') for s in ndbc],\n",
    "    )\n",
    "\n",
    "table = pd.DataFrame(data).set_index('station_code')\n",
    "to_html(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoopsSoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyoos.collectors.coops.coops_sos import CoopsSos\n",
    "\n",
    "collector_coops = CoopsSos()\n",
    "\n",
    "collector_coops.set_bbox(config['region']['bbox'])\n",
    "collector_coops.end_time = config['date']['stop']\n",
    "collector_coops.start_time = config['date']['start']\n",
    "collector_coops.variables = [config['sos_name']]\n",
    "\n",
    "ofrs = collector_coops.server.offerings\n",
    "title = collector_coops.server.identification.title\n",
    "print(fmt(' Collector offerings '))\n",
    "print('{}: {} offerings'.format(title, len(ofrs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coops = collector2table(collector=collector_coops,\n",
    "                        config=config,\n",
    "                        col='sea_water_temperature (C)')\n",
    "\n",
    "if coops:\n",
    "    data = dict(\n",
    "        station_name=[s._metadata.get('station_name') for s in coops],\n",
    "        station_code=[s._metadata.get('station_code') for s in coops],\n",
    "        sensor=[s._metadata.get('sensor') for s in coops],\n",
    "        lon=[s._metadata.get('lon') for s in coops],\n",
    "        lat=[s._metadata.get('lat') for s in coops],\n",
    "        depth=[s._metadata.get('depth') for s in coops],\n",
    "    )\n",
    "\n",
    "table = pd.DataFrame(data).set_index('station_code')\n",
    "to_html(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join CoopsSoS and NdbcSos in uniform 1-hour time base series for model/data comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = ndbc + coops\n",
    "\n",
    "index = pd.date_range(start=config['date']['start'].replace(tzinfo=None),\n",
    "                      end=config['date']['stop'].replace(tzinfo=None),\n",
    "                      freq='1H')\n",
    "\n",
    "# Preserve metadata with `reindex`.\n",
    "observations = []\n",
    "for series in data:\n",
    "    _metadata = series._metadata\n",
    "    obs = series.reindex(index=index, limit=1, method='nearest')\n",
    "    obs._metadata = _metadata\n",
    "    observations.append(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save simpler station code/name file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import iris\n",
    "from ioos_tools.tardis import series2cube\n",
    "\n",
    "attr = dict(\n",
    "    featureType='timeSeries',\n",
    "    Conventions='CF-1.6',\n",
    "    standard_name_vocabulary='CF-1.6',\n",
    "    cdm_data_type=\"Station\",\n",
    "    comment=\"Data from http://opendap.co-ops.nos.noaa.gov\"\n",
    ")\n",
    "\n",
    "print(fmt(' Observations '))\n",
    "outfile = os.path.join(save_dir, 'OBS_DATA.nc')\n",
    "\n",
    "cubes = iris.cube.CubeList(\n",
    "    [series2cube(obs, attr=attr) for obs in observations]\n",
    ")\n",
    "\n",
    "iris.save(cubes, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop discovered models and save the nearest time-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from iris.exceptions import (CoordinateNotFoundError, ConstraintMismatchError,\n",
    "                             MergeError)\n",
    "from ioos_tools.ioos import get_model_name\n",
    "from ioos_tools.tardis import quick_load_cubes, proc_cube, is_model, get_surface\n",
    "\n",
    "print(fmt(' Models '))\n",
    "cubes = dict()\n",
    "for k, url in enumerate(dap_urls):\n",
    "    print('\\n[Reading url {}/{}]: {}'.format(k+1, len(dap_urls), url))\n",
    "    try:\n",
    "        cube = quick_load_cubes(url, config['cf_names'],\n",
    "                                callback=None, strict=True)\n",
    "        if is_model(cube):\n",
    "            cube = proc_cube(cube,\n",
    "                             bbox=config['region']['bbox'],\n",
    "                             time=(config['date']['start'],\n",
    "                                   config['date']['stop']),\n",
    "                             units=config['units'])\n",
    "        else:\n",
    "            log.warning(\"[Not model data]: {}\".format(url))\n",
    "            continue\n",
    "        cube = get_surface(cube)\n",
    "        mod_name = get_model_name(url)\n",
    "        cubes.update({mod_name: cube})\n",
    "    except (RuntimeError, ValueError,\n",
    "            ConstraintMismatchError, CoordinateNotFoundError,\n",
    "            IndexError) as e:\n",
    "        log.warning('Cannot get cube for: {}\\n{}'.format(url, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import iris\n",
    "from iris.pandas import as_series\n",
    "from ioos_tools.tardis import (make_tree, get_nearest_water,\n",
    "                               add_station, ensure_timeseries, remove_ssh)\n",
    "\n",
    "for mod_name, cube in cubes.items():\n",
    "    fname = '{}.nc'.format(mod_name)\n",
    "    fname = os.path.join(save_dir, fname)\n",
    "    print(fmt(' Downloading to file {} '.format(fname)))\n",
    "    try:\n",
    "        tree, lon, lat = make_tree(cube)\n",
    "    except CoordinateNotFoundError as e:\n",
    "        log.warning('Cannot make KDTree for: {}'.format(mod_name))\n",
    "        continue\n",
    "    # Get model series at observed locations.\n",
    "    raw_series = dict()\n",
    "    for obs in observations:\n",
    "        obs = obs._metadata\n",
    "        station = obs['station_code']\n",
    "        try:\n",
    "            kw = dict(k=10, max_dist=0.08, min_var=0.01)\n",
    "            args = cube, tree, obs['lon'], obs['lat']\n",
    "            try:\n",
    "                series, dist, idx = get_nearest_water(*args, **kw)\n",
    "            except RuntimeError as e:\n",
    "                print('Cannot download {!r}.\\n{}'.format(cube, e))\n",
    "                series = None\n",
    "        except ValueError as e:\n",
    "            status = \"No Data\"\n",
    "            print('[{}] {}'.format(status, obs['station_name']))\n",
    "            continue\n",
    "        if not series:\n",
    "            status = \"Land   \"\n",
    "        else:\n",
    "            raw_series.update({station: series})\n",
    "            series = as_series(series)\n",
    "            status = \"Water  \"\n",
    "        print('[{}] {}'.format(status, obs['station_name']))\n",
    "    if raw_series:  # Save cube.\n",
    "        for station, cube in raw_series.items():\n",
    "            cube = add_station(cube, station)\n",
    "            cube = remove_ssh(cube)\n",
    "        try:\n",
    "            cube = iris.cube.CubeList(raw_series.values()).merge_cube()\n",
    "        except MergeError as e:\n",
    "            log.warning(e)\n",
    "        ensure_timeseries(cube)\n",
    "        iris.save(cube, fname)\n",
    "        del cube\n",
    "    print('Finished processing [{}]'.format(mod_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ioos_tools.ioos import parse_config\n",
    "\n",
    "config = parse_config('config.yaml')\n",
    "\n",
    "save_dir = os.path.join(os.path.abspath(config['run_name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skill 1: Model Bias (or Mean Bias)\n",
    "\n",
    "The bias skill compares the model mean temperature against the observations.\n",
    "It is possible to introduce a Mean Bias in the model due to a mismatch of the\n",
    "boundary forcing and the model interior.\n",
    "\n",
    "$$ \\text{MB} = \\mathbf{\\overline{m}} - \\mathbf{\\overline{o}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ioos_tools.ioos import stations_keys\n",
    "\n",
    "\n",
    "def rename_cols(df, config):\n",
    "    cols = stations_keys(config, key='station_name')\n",
    "    return df.rename(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ioos_tools.ioos import to_html, save_html, load_ncs\n",
    "from ioos_tools.skill_score import mean_bias, apply_skill\n",
    "\n",
    "dfs = load_ncs(config)\n",
    "\n",
    "df = apply_skill(dfs, mean_bias, remove_mean=False, filter_tides=False)\n",
    "skill_score = dict(mean_bias=df.to_dict())\n",
    "\n",
    "# Filter out stations with no valid comparison.\n",
    "df.dropna(how='all', axis=1, inplace=True)\n",
    "df = df.applymap('{:.2f}'.format).replace('nan', '--')\n",
    "\n",
    "# Pretty HTML table.\n",
    "if not df.empty:\n",
    "    df = rename_cols(df, config)\n",
    "    html = to_html(df.T)\n",
    "    fname = os.path.join(save_dir, 'mean_bias.html')\n",
    "    save_html(fname, html)\n",
    "    html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skill 2: Central Root Mean Squared Error\n",
    "\n",
    "Root Mean Squared Error of the deviations from the mean.\n",
    "\n",
    "$$ \\text{CRMS} = \\sqrt{\\left(\\mathbf{m'} - \\mathbf{o'}\\right)^2}$$\n",
    "\n",
    "where: $\\mathbf{m'} = \\mathbf{m} - \\mathbf{\\overline{m}}$ and $\\mathbf{o'} = \\mathbf{o} - \\mathbf{\\overline{o}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ioos_tools.skill_score import rmse\n",
    "\n",
    "dfs = load_ncs(config)\n",
    "\n",
    "df = apply_skill(dfs, rmse, remove_mean=True, filter_tides=False)\n",
    "skill_score['rmse'] = df.to_dict()\n",
    "\n",
    "# Filter out stations with no valid comparison.\n",
    "df.dropna(how='all', axis=1, inplace=True)\n",
    "df = df.applymap('{:.2f}'.format).replace('nan', '--')\n",
    "\n",
    "# Pretty HTML table.\n",
    "if not df.empty:\n",
    "    df = rename_cols(df, config)\n",
    "    html = to_html(df.T)\n",
    "    fname = os.path.join(save_dir, 'rmse.html')\n",
    "    save_html(fname, html)\n",
    "    html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skill 3: R$^2$\n",
    "https://en.wikipedia.org/wiki/Coefficient_of_determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ioos_tools.skill_score import r2\n",
    "\n",
    "dfs = load_ncs(config)\n",
    "\n",
    "df = apply_skill(dfs, r2, remove_mean=True, filter_tides=False)\n",
    "skill_score['r2'] = df.to_dict()\n",
    "\n",
    "# Filter out stations with no valid comparison.\n",
    "df.dropna(how='all', axis=1, inplace=True)\n",
    "df = df.applymap('{:.2f}'.format).replace('nan', '--')\n",
    "\n",
    "# Pretty HTML table.\n",
    "if not df.empty:\n",
    "    df = rename_cols(df, config)\n",
    "    html = to_html(df.T)\n",
    "    fname = os.path.join(save_dir, 'r2.html')\n",
    "    save_html(fname, html)\n",
    "    html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "fname = os.path.join(save_dir, 'skill_score.json')\n",
    "\n",
    "# Stringfy keys for json.\n",
    "for key in skill_score.keys():\n",
    "    skill_score[key] = {str(k): v for k, v in skill_score[key].items()}\n",
    "\n",
    "with open(fname, 'w') as f:\n",
    "    f.write(json.dumps(skill_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Taylor diagrams\n",
    "\n",
    "The radius is model standard deviation error divided  by observations deviation,\n",
    "azimuth is arc-cosine of cross correlation (R), and distance to point (1, 0) on the\n",
    "abscissa is Centered RMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from ioos_tools.taylor_diagram import TaylorDiagram\n",
    "\n",
    "\n",
    "def make_taylor(samples):\n",
    "    fig = plt.figure(figsize=(9, 9))\n",
    "    dia = TaylorDiagram(samples['std']['OBS_DATA'],\n",
    "                        fig=fig,\n",
    "                        label=\"Observation\")\n",
    "    # Add samples to Taylor diagram.\n",
    "    samples.drop('OBS_DATA', inplace=True)\n",
    "    for model, row in samples.iterrows():\n",
    "        dia.add_sample(row['std'], row['corr'], marker='s', ls='',\n",
    "                       label=model)\n",
    "    # Add RMS contours, and label them.\n",
    "    contours = dia.add_contours(colors='0.5')\n",
    "    plt.clabel(contours, inline=1, fontsize=10)\n",
    "    # Add a figure legend.\n",
    "    kw = dict(prop=dict(size='small'), loc='upper right')\n",
    "    fig.legend(dia.samplePoints,\n",
    "               [p.get_label() for p in dia.samplePoints],\n",
    "               numpoints=1, **kw)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dfs = load_ncs(config)\n",
    "\n",
    "# Bin and interpolate all series.\n",
    "freq = '30min'\n",
    "for station, df in list(dfs.iteritems()):\n",
    "    df = df.resample(freq).interpolate().dropna(axis=1)\n",
    "    if 'OBS_DATA' in df:\n",
    "        samples = pd.DataFrame.from_dict(dict(std=df.std(),\n",
    "                                              corr=df.corr()['OBS_DATA']))\n",
    "    else:\n",
    "        continue\n",
    "    samples[samples < 0] = np.NaN\n",
    "    samples.dropna(inplace=True)\n",
    "    if len(samples) <= 2:  # 1 obs 1 model.\n",
    "        continue\n",
    "    fig = make_taylor(samples)\n",
    "    fig.savefig(os.path.join(save_dir, '{}.png'.format(station)))\n",
    "    plt.close(fig)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load skill_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "fname = os.path.join(config['run_name'], 'skill_score.json')\n",
    "with open(fname, 'r') as f:\n",
    "    skill_score = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mean_bias = pd.DataFrame.from_dict(skill_score['mean_bias'])\n",
    "mean_bias = mean_bias.applymap('{:.2f}'.format).replace('nan', '--')\n",
    "\n",
    "skill_score = pd.DataFrame.from_dict(skill_score['rmse'])\n",
    "skill_score = skill_score.applymap('{:.2f}'.format).replace('nan', '--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ioos_tools.ioos import make_map\n",
    "\n",
    "bbox = config['region']['bbox']\n",
    "units = config['units']\n",
    "run_name = config['run_name']\n",
    "\n",
    "kw = dict(zoom_start=11, line=True, states=False,\n",
    "          secoora_stations=False, layers=False)\n",
    "mapa = make_map(bbox, **kw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_obs = stations_keys(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from operator import itemgetter\n",
    "\n",
    "import iris\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "iris.FUTURE.netcdf_promote = True\n",
    "\n",
    "big_list = []\n",
    "for fname in glob(os.path.join(save_dir, \"*.nc\")):\n",
    "    if 'OBS_DATA' in fname:\n",
    "        continue\n",
    "    cube = iris.load_cube(fname)\n",
    "    model = fname.split('-')[-1].split('.')[0]\n",
    "    lons = cube.coord(axis='X').points\n",
    "    lats = cube.coord(axis='Y').points\n",
    "    stations = cube.coord('station_code').points\n",
    "    models = [model]*lons.size\n",
    "    lista = zip(models, lons.tolist(), lats.tolist(), stations.tolist())\n",
    "    big_list.extend(lista)\n",
    "\n",
    "big_list.sort(key=itemgetter(3))\n",
    "df = pd.DataFrame(big_list, columns=['name', 'lon', 'lat', 'station'])\n",
    "df.set_index('station', drop=True, inplace=True)\n",
    "groups = df.groupby(df.index)\n",
    "\n",
    "\n",
    "locations, popups = [], []\n",
    "for station, info in groups:\n",
    "    sta_name = all_obs[station]\n",
    "    for lat, lon, name in zip(info.lat, info.lon, info.name):\n",
    "        locations.append([lat, lon])\n",
    "        popups.append('[{}]: {}'.format(name, sta_name))\n",
    "\n",
    "MarkerCluster(locations=locations, popups=popups).add_to(mapa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and observations plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppresing warnings for a \"pretty output.\"\n",
    "# Remove this line to debug any possible issues.\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Legend dictionary. If any new model is found we will use its filename as legend.\n",
    "# Here we only provide some nice names for the models we expect to find.\n",
    "\n",
    "titles = {\n",
    "    'coawst_4_use_best': 'COAWST_4',\n",
    "    'global': 'HYCOM',\n",
    "    'NECOFS_GOM3_FORECAST': 'NECOFS_GOM3',\n",
    "    'NECOFS_FVCOM_OCEAN_MASSBAY_FORECAST': 'NECOFS_MassBay',\n",
    "    'OBS_DATA': 'Observations'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bokeh.resources import CDN\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.embed import file_html\n",
    "from bokeh.models import HoverTool\n",
    "from itertools import cycle\n",
    "from bokeh.palettes import Spectral6\n",
    "\n",
    "from folium.element import IFrame\n",
    "\n",
    "# Plot defaults.\n",
    "colors = Spectral6\n",
    "colorcycler = cycle(colors)\n",
    "tools = \"pan,box_zoom,reset\"\n",
    "width, height = 750, 250\n",
    "\n",
    "\n",
    "def make_plot(df, station):\n",
    "    p = figure(toolbar_location=\"above\",\n",
    "               x_axis_type=\"datetime\",\n",
    "               width=width,\n",
    "               height=height,\n",
    "               tools=tools,\n",
    "               title=str(station))\n",
    "    for column, series in df.iteritems():\n",
    "        series.dropna(inplace=True)\n",
    "        if not series.empty:\n",
    "            line = p.line(\n",
    "                x=series.index,\n",
    "                y=series.values,\n",
    "                legend=\"%s\" % titles.get(column, column),\n",
    "                line_color=next(colorcycler),\n",
    "                line_width=5,\n",
    "                line_cap='round',\n",
    "                line_join='round'\n",
    "            )\n",
    "            if 'OBS_DATA' not in column:\n",
    "                bias = mean_bias[str(station)][column]\n",
    "                skill = skill_score[str(station)][column]\n",
    "            else:\n",
    "                skill = bias = 'NA'\n",
    "            p.add_tools(HoverTool(tooltips=[(\"Name\", \"%s\" % column),\n",
    "                                            (\"Bias\", bias),\n",
    "                                            (\"Skill\", skill)],\n",
    "                                  renderers=[line]))\n",
    "    return p\n",
    "\n",
    "\n",
    "def make_marker(p, station):\n",
    "    lons = stations_keys(config, key='lon')\n",
    "    lats = stations_keys(config, key='lat')\n",
    "\n",
    "    lon, lat = lons[station], lats[station]\n",
    "    html = file_html(p, CDN, station)\n",
    "    iframe = IFrame(html, width=width+40, height=height+80)\n",
    "\n",
    "    popup = folium.Popup(iframe, max_width=2650)\n",
    "    icon = folium.Icon(color='green', icon='stats')\n",
    "    marker = folium.Marker(location=[lat, lon],\n",
    "                           popup=popup,\n",
    "                           icon=icon)\n",
    "    return marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfs = load_ncs(config)\n",
    "\n",
    "for station in dfs:\n",
    "    sta_name = all_obs[station]\n",
    "    df = dfs[station]\n",
    "    if df.empty:\n",
    "        continue\n",
    "    p = make_plot(df, station)\n",
    "    maker = make_marker(p, station)\n",
    "    maker.add_to(mapa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elapsed = time.time() - start_time\n",
    "print('{:.2f} minutes'.format(elapsed/60.))\n",
    "print('EOF')\n",
    "\n",
    "logfile = os.path.join(config['run_name'], 'log.txt')\n",
    "\n",
    "with open(logfile) as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Right click and choose Save link as... to\n",
    "[download](https://raw.githubusercontent.com/ioos/notebooks_demos/master/notebooks/2016-12-22-boston_light_swim.ipynb)\n",
    "this notebook, or see a static view [here](http://nbviewer.ipython.org/urls/raw.githubusercontent.com/ioos/notebooks_demos/master/notebooks/2016-12-22-boston_light_swim.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
