{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aligning Data to Darwin Core - Sampling Event with Measurement or Fact using Python\n",
    "Mathew Biddle\n",
    "\n",
    "January 19, 2021\n",
    "\n",
    "# General information about this notebook\n",
    "This notebook was created for the [IOOS DMAC Code Sprint](https://www.glos.us/code-sprint/) Biological Data Session\n",
    "The data in this notebook were created specifically as an example and meant solely to be\n",
    "illustrative of the process for aligning data to the biological data standard - [Darwin Core](https://dwc.tdwg.org/).\n",
    "These data should not be considered actually occurrences of species and any measurements\n",
    "are also contrived. This notebook is meant to provide a step by step process for taking\n",
    "original data and aligning it to Darwin Core\n",
    "\n",
    "This notebook is a python implementation of the R notebook [IOOS_DMAC_DataToDWC_Notebook_event.R](https://github.com/ioos/bio_data_guide/blob/master/Standardizing%20Marine%20Biological%20Data/datasets/example_script_with_fake_data/IOOS_DMAC_DataToDwC_Notebook_event.R)\n",
    "\n",
    "First let's bring in the appropriate libraries to work with the tabular data files and generate the appropriate content for the DarwinCore requirements.\n",
    "\n",
    "_Note: [pyworms](https://github.com/iobis/pyworms) was installed using `pip install git+git://github.com/iobis/pyworms.git` to get the most recent version from GitHub._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyworms\n",
    "import numpy as np\n",
    "import uuid\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to read in the raw data file using [pandas.read_csv()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'data/MadeUpDataForBiologicalDataTraining.csv'\n",
    "df = pd.read_csv(file, header=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to to decide if we will provide an **occurrence only** version of the data or a **sampling event with measurement or facts** version of the data. \n",
    "\n",
    "* **Occurrence** only is easier to create. It's only one file to produce. However, several pieces of information will be left out if we choose that option. \n",
    "* If we choose to do **sampling event with measurement or fact** we'll be able to capture all of the data in the file creating a lossless version.\n",
    "\n",
    "Here we decide to use the **sampling event** option to include as much information as we can.\n",
    "\n",
    "First let's create the `eventID` and `occurrenceID` in the original file so that information can be reused for all necessary files down the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['eventID'] = df[['region', 'station', 'transect']].apply(lambda x: '_'.join(x.astype(str)), axis=1)\n",
    "df['occurrenceID'] = uuid.uuid4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to create *three* separate files to comply with the **sampling event** format.\n",
    "We'll start with the **event file** but we only need to include the columns that are relevant\n",
    "to the event file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first make a copy of the dataFrame we pulled in. Only using the data fields of interest for the **event file**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = df[['date', 'lat', 'lon', 'region', 'station', 'transect', 'depth', 'bottom type', 'eventID']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to rename any columns of data to match directly to Darwin Core."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "event['decimalLatitude'] = event['lat']\n",
    "event['decimalLongitude'] = event['lon']\n",
    "event['minimumDepthInMeters'] = event['depth']\n",
    "event['maximumDepthInMeters'] = event['depth']\n",
    "event['habitat'] = event['bottom type']\n",
    "event['island'] = event['region']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert the date to ISO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "event['eventDate'] = pd.to_datetime(\n",
    "                            event['date'],\n",
    "                            format='%m/%d/%Y',\n",
    "                            utc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also have to add any missing required fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "event['basisOfRecord'] = 'HumanObservation'\n",
    "event['geodeticDatum'] = 'EPSG:4326 WGS84'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll remove any columns that we no longer need to clean things up a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "event.drop(\n",
    "    columns=['date', 'lat', 'lon', 'region', 'station', 'transect', 'depth', 'bottom type'],\n",
    "    inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have too many repeating rows of information. We can pare this down using eventID which\n",
    "is a unique identifier for each sampling event in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'event' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-393f8ea15f54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m event.drop_duplicates(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'eventID'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     inplace=True)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'event' is not defined"
     ]
    }
   ],
   "source": [
    "event.drop_duplicates(\n",
    "    subset='eventID',\n",
    "    inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we write out the event file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#event.to_csv(\n",
    "#    'MadeUpData_event_frompy.csv',\n",
    "#    header=True,\n",
    "#    index=False,\n",
    "#    date_format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Occurrence file\n",
    "Next we need to create the occurrence file. We start by creating the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurrence = df[['scientific name', 'eventID', 'occurrenceID', 'percent cover']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll rename the columns that align directly with Darwin Core."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurrence['scientificName'] = occurrence['scientific name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we'll add required information that's missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurrence['occurrenceStatus'] = np.where(occurrence['percent cover'] == 0, 'absent', 'present')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taxonomic Name Matching\n",
    "A requirement for OBIS is that all scientific names match to the World Register of\n",
    "Marine Species (WoRMS) and a scientificNameID is included. A scientificNameID looks\n",
    "like this \"urn:lsid:marinespecies.org:taxname:275730\" with the last digits after\n",
    "the colon being the WoRMS aphia ID. We'll need to go out to WoRMS to grab this\n",
    "information.\n",
    "\n",
    "Create a lookup table of unique scientific names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lut_worms = pd.DataFrame(\n",
    "    columns=['scientificName'],\n",
    "    data=occurrence['scientificName'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the columns that we can grab information from WoRMS including the required scientificNameID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['acceptedname', 'acceptedID', 'scientificNameID', 'kingdom', 'phylum',\n",
    "           'class', 'order', 'family', 'genus', 'scientificNameAuthorship', 'taxonRank']\n",
    "\n",
    "for head in headers:\n",
    "    lut_worms[head] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taxonomic lookup using the library [pyworms](https://github.com/iobis/pyworms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for scientific name = Acropora cervicornis\n",
      "Searching for scientific name = Madracis auretenra\n",
      "Searching for scientific name = Mussa angulosa\n",
      "Searching for scientific name = Siderastrea radians\n"
     ]
    }
   ],
   "source": [
    "for index, row in lut_worms.iterrows():\n",
    "    print('Searching for scientific name = %s' % row['scientificName'])\n",
    "    resp = pyworms.aphiaRecordsByMatchNames(row['scientificName'])[0][0]\n",
    "    lut_worms.loc[index, 'acceptedname'] = resp['valid_name']\n",
    "    lut_worms.loc[index, 'acceptedID'] = resp['valid_AphiaID']\n",
    "    lut_worms.loc[index, 'scientificNameID'] = resp['lsid']\n",
    "    lut_worms.loc[index, 'kingdom'] = resp['kingdom']\n",
    "    lut_worms.loc[index, 'phylum'] = resp['phylum']\n",
    "    lut_worms.loc[index, 'class'] = resp['class']\n",
    "    lut_worms.loc[index, 'order'] = resp['order']\n",
    "    lut_worms.loc[index, 'family'] = resp['family']\n",
    "    lut_worms.loc[index, 'genus'] = resp['genus']\n",
    "    lut_worms.loc[index, 'scientificNameAuthorship'] = resp['authority']\n",
    "    lut_worms.loc[index, 'taxonRank'] = resp['rank']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the lookup table of unique scientific names back with the occurrence data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurrence = pd.merge(occurrence, lut_worms, how='left', on='scientificName')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to remove any unnecessary columns to clean up the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurrence.drop(\n",
    "    columns=['scientific name', 'percent cover'],\n",
    "    inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write out the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the columns on scientificName\n",
    "occurrence.sort_values('scientificName', inplace=True)\n",
    "\n",
    "# reorganize column order to be consistent with R example:\n",
    "columns = [\"scientificName\",\"eventID\",\"occurrenceID\",\"occurrenceStatus\",\"acceptedname\",\"acceptedID\",\n",
    "           \"scientificNameID\",\"kingdom\",\"phylum\",\"class\",\"order\",\"family\",\"genus\",\"scientificNameAuthorship\",\n",
    "           \"taxonRank\"]\n",
    "\n",
    "#occurrence.to_csv(\n",
    "#    \"MadeUpData_Occurrence_frompy.csv\",\n",
    "#    header=True,\n",
    "#    index=False,\n",
    "#    quoting=csv.QUOTE_ALL,\n",
    "#    columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " All done with occurrence!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measurement Or Fact\n",
    "The last file we need to create is the measurement or fact file. For this we need to\n",
    "combine all of the measurements or facts that we want to include making sure to include\n",
    "IDs from the BODC NERC vocabulary where possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = df[['eventID', 'temperature', 'date']].copy()\n",
    "temperature['occurrenceID'] = ''\n",
    "temperature['measurementType'] = 'temperature'\n",
    "temperature['measurementTypeID'] = 'http://vocab.nerc.ac.uk/collection/P25/current/WTEMP/'\n",
    "temperature['measurementValue'] = temperature['temperature']\n",
    "temperature['measurementUnit'] = 'Celsius'\n",
    "temperature['measurementUnitID'] = 'http://vocab.nerc.ac.uk/collection/P06/current/UPAA/'\n",
    "temperature['measurementAccuracy'] = 3\n",
    "temperature['measurementDeterminedDate'] = pd.to_datetime(temperature['date'],\n",
    "                                                          format='%m/%d/%Y',\n",
    "                                                          utc=True)\n",
    "temperature['measurementMethod'] = ''\n",
    "temperature.drop(\n",
    "    columns=['temperature', 'date'],\n",
    "    inplace=True)\n",
    "\n",
    "rugosity = df[['eventID', 'rugosity', 'date']].copy()\n",
    "rugosity['occurrenceID'] = ''\n",
    "rugosity['measurementType'] = 'rugosity'\n",
    "rugosity['measurementTypeID'] = ''\n",
    "rugosity['measurementValue'] = rugosity['rugosity'].map('{:,.6f}'.format)\n",
    "rugosity['measurementUnit'] = ''\n",
    "rugosity['measurementUnitID'] = ''\n",
    "rugosity['measurementAccuracy'] = ''\n",
    "rugosity['measurementDeterminedDate'] = pd.to_datetime(rugosity['date'],\n",
    "                                                       format='%m/%d/%Y',\n",
    "                                                       utc=True)\n",
    "rugosity['measurementMethod'] = ''\n",
    "rugosity.drop(\n",
    "    columns=['rugosity', 'date'],\n",
    "    inplace=True)\n",
    "\n",
    "percent_cover = df[['eventID', 'occurrenceID', 'percent cover', 'date']].copy()\n",
    "percent_cover['measurementType'] = 'Percent Cover'\n",
    "percent_cover['measurementTypeID'] = 'http://vocab.nerc.ac.uk/collection/P01/current/SDBIOL10/'\n",
    "percent_cover['measurementValue'] = percent_cover['percent cover']\n",
    "percent_cover['measurementUnit'] = 'Percent/100m^2'\n",
    "percent_cover['measurementUnitID'] = ''\n",
    "percent_cover['measurementAccuracy'] = 5\n",
    "percent_cover['measurementDeterminedDate'] = pd.to_datetime(percent_cover['date'],\n",
    "                                                          format='%m/%d/%Y',\n",
    "                                                          utc=True)\n",
    "percent_cover['measurementMethod'] = ''\n",
    "percent_cover.drop(\n",
    "    columns=['percent cover', 'date'],\n",
    "    inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate all measurements or facts together into one dataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurementorfact = pd.concat([temperature, rugosity, percent_cover])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write measurement or fact file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measurementorfact.to_csv('MadeUpDate_mof_frompy.csv',\n",
    "#                          index=False,\n",
    "#                          header=True,\n",
    "#                          date_format='%Y-%m-%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
